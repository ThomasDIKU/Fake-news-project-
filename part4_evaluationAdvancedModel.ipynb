{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and read the test file"
      ],
      "metadata": {
        "id": "lsG2OrSTlsp5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKcJIBBEiTSz",
        "outputId": "d82e4540-89d9-408d-ef15-931f9c216189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "0        ['``', 'subobject', \"''\", 'predefin', 'propert...\n",
            "1        ['decis', 'import', 'liquefi', 'natur', 'ga', ...\n",
            "2        ['cnn', 'get', 'faa', 'waiver', 'fli', 'drone'...\n",
            "3        ['headlin', ':', 'work', 'american', 'stand', ...\n",
            "4        ['tom', 'clanci', '’', 'divis', 'best', 'day',...\n",
            "                               ...                        \n",
            "51022    ['planet', 'x', 'visibl', ',', 'may', '<num>',...\n",
            "51023    ['<num>', ',', 'time', 'life', 'jade', ',', 'w...\n",
            "51024    ['president-elect', 'donald', 'trump', '’', 'n...\n",
            "51025    ['search', 'properti', 'list', 'page', 'proper...\n",
            "51026    ['maureen', 'dowd', 'screen', '“', 'fair', 'ga...\n",
            "Name: content, Length: 51027, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_test = pd.read_csv(\"/content/drive/My Drive/995,000_rows_preprocessed_test.csv\", usecols=[\"type\", \"content\"]) #Read the CSV file\n",
        "\n",
        "model = load_model(\"/content/drive/My Drive/my_model_v2.keras\") #Load the model\n",
        "print(data_test['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classify our types into binary. We use 1 for reliable news, 0 for fake news. Check for missing values and them to 0.0"
      ],
      "metadata": {
        "id": "dQbWD9Hfl32T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipi3OCQdiTS1",
        "outputId": "9787ea66-7d60-45c5-8f62-c182e5f91a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 51027 entries, 0 to 51026\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   type     51027 non-null  float64\n",
            " 1   content  51027 non-null  object \n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 797.4+ KB\n",
            "15085.0\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load your dataset (assuming df is your DataFrame)\n",
        "#df = data.dropna(subset=['type', 'content']).copy()\n",
        "\n",
        "def Classificationtype(df):\n",
        "  df['type'] = df['type'].map({\n",
        "      'unreliable': 0.0,\n",
        "      'fake': 0.0,\n",
        "      'clickbait': 1.0,\n",
        "      'conspiracy': 0.0,\n",
        "      'bias': 0.0,\n",
        "      'hate': 0.0,\n",
        "      'junksci': 0.0,\n",
        "      'political': 1.0,\n",
        "      'unknown': 0.0,\n",
        "      'reliable': 1.0\n",
        "  })\n",
        "\n",
        "  # Replace NaN values with \"unknown\"\n",
        "  df.fillna(0.0, inplace=True)\n",
        "\n",
        "  # Verify the changes\n",
        "  df.info()\n",
        "\n",
        "\n",
        "Classificationtype(data_test)\n",
        "\n",
        "\n",
        "print(sum(data_test['type']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the tokenizer and apply to test data\n"
      ],
      "metadata": {
        "id": "quCvFNWfmEL4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfLLJDLniTS2",
        "outputId": "62be3cfc-ec24-478a-8097-2f7910a525db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Load the tokenizer from the file\n",
        "# Update the path to include your Drive location\n",
        "with open('/content/drive/My Drive/tokenizer.pkl', 'rb') as f:  # Make sure this line is not indented\n",
        "    tokenizer = pickle.load(f)  # This line should be indented\n",
        "\n",
        "print(\"Tokenizer loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lu2I3XzbiTS2"
      },
      "outputs": [],
      "source": [
        "X_test_seq = tokenizer.texts_to_sequences(data_test['content'])\n",
        "X_padded_test = pad_sequences(X_test_seq, maxlen=1700)\n",
        "X_test = X_padded_test\n",
        "y_test = data_test['type'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate the accuracy\n"
      ],
      "metadata": {
        "id": "j_rQ1sIEmOfy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xLxZHCObiTS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8566bdc2-3442-44f3-a6b1-f03992d6f015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1595/1595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8953 - loss: 0.2577\n",
            "Test Accuracy: 89.54%\n",
            "\u001b[1m1595/1595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step\n",
            "F1 Score: 0.82\n",
            "Confusion Matrix:\n",
            " [[33516  2426]\n",
            " [ 2911 12174]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}