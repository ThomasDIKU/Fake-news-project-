{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find top 10000 vocab + Logistic Rgression\n",
    "\n",
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import requests\n",
    "import ast\n",
    "\n",
    "# Download nltk packages if necessary\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# ---- 1. Load and prepare data ----\n",
    "\n",
    "# Mapping of types to \"fake\" or \"reliable\"\n",
    "type_mapping = {\n",
    "    'unreliable': 'fake',\n",
    "    'fake': 'fake',\n",
    "    'conspiracy': 'fake',\n",
    "    'bias': 'fake',\n",
    "    'junksci': 'fake',\n",
    "    'clickbait': 'reliable',\n",
    "    'reliable' : 'reliable',\n",
    "    'state': 'fake',\n",
    "    'political': 'reliable',\n",
    "    'satire': 'fake',\n",
    "    'hate': 'fake',\n",
    "    'rumor': 'fake',\n",
    "}\n",
    "\n",
    "# Load data and filter relevant columns\n",
    "data = pd.read_csv(\"15,000_rows_preprocessed.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "#data = pd.read_csv(\"995,000_rows_preprocessed.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "\n",
    "# Load BBC-data and add to dataset\n",
    "bbc_data = pd.read_csv(\"BBC_preprocessed.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "data = pd.concat([data, bbc_data], ignore_index=True)\n",
    "\n",
    "# Remove rows with unknown type\n",
    "data = data[data['type'] != 'unknown']\n",
    "\n",
    "# Map types to labels\n",
    "data[\"label\"] = data[\"type\"].map(type_mapping)\n",
    "\n",
    "# Remove NaN\n",
    "data = data.dropna(subset=[\"label\"])\n",
    "\n",
    "# ---- 2. Split dataset to training, validation and test (80/10/10) ----\n",
    "\n",
    "train, valid, test = np.split(\n",
    "    data.sample(frac=1, random_state=42),  # Shuffle\n",
    "    [int(0.8 * len(data)), int(0.9 * len(data))]  # Index for split\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load \"LIAR\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation data from LIAR-dataset\n",
    "\n",
    "liar_test_data = pd.read_csv(\"liar_test_data_preprocessed.csv\", usecols=['type', 'content'], dtype=str)\n",
    "\n",
    "type_mapping_liar = {\n",
    "    'true': 'reliable', \n",
    "    'false': 'fake', \n",
    "    'half-true': 'fake', \n",
    "    'pants-fire': 'fake', \n",
    "    'barely-true': 'reliable',\n",
    "    'mostly-true': 'reliable'\n",
    "}\n",
    "\n",
    "liar_test_data[\"label\"] = liar_test_data[\"type\"].map(type_mapping_liar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# ---- 3. Convert text to Bag-of-Words feature matrix ----\n",
    "\n",
    "content_as_lists = data['content'].apply(ast.literal_eval)\n",
    "\n",
    "all_words = content_as_lists.explode().tolist()\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "top_10000_words = [word for word, _ in word_counts.most_common(10000)]\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=top_10000_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training, valid og test data\n",
    "X_train = vectorizer.transform(train['content'])\n",
    "X_valid = vectorizer.transform(valid['content'])\n",
    "X_test = vectorizer.transform(test['content'])\n",
    "\n",
    "# Transform LIAR test data to Bag-of-Words\n",
    "X_test_liar = vectorizer.transform(liar_test_data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total F1-score: 0.49159389082685817\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.48      0.32      0.38       606\n",
      "    reliable       0.52      0.69      0.59       661\n",
      "\n",
      "    accuracy                           0.51      1267\n",
      "   macro avg       0.50      0.50      0.49      1267\n",
      "weighted avg       0.50      0.51      0.49      1267\n",
      "\n",
      "Confusion Matrix:\n",
      "[[191 415]\n",
      " [207 454]]\n",
      "Original test with test set - classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.83      0.75      0.79       676\n",
      "    reliable       0.78      0.85      0.81       694\n",
      "\n",
      "    accuracy                           0.80      1370\n",
      "   macro avg       0.80      0.80      0.80      1370\n",
      "weighted avg       0.80      0.80      0.80      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# LIAR not scaled\n",
    "\n",
    "# Labels\n",
    "y_train = train['label']\n",
    "y_valid = valid['label']\n",
    "y_test = test['label']\n",
    "\n",
    "y_test_liar = liar_test_data['label']\n",
    "\n",
    "# ---- 4. Train Logistic Regression model ----\n",
    "\n",
    "clf = LogisticRegression(max_iter=100000, solver='saga', random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ---- 5. Evaluate model ----\n",
    "\n",
    "y_pred_liar = clf.predict(X_test_liar)\n",
    "\n",
    "# ---- 6. Evaluate model on LIAR test. Notice that it isn't scaled since scaling gave an even worse result ----\n",
    "\n",
    "f1 = f1_score(y_test_liar, y_pred_liar, average='weighted')  # eller 'macro'\n",
    "print(\"Total F1-score: LIAR dataset:\", f1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_liar, y_pred_liar))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_liar, y_pred_liar))\n",
    "\n",
    "\n",
    "\n",
    "# ---- Original test with test set (remove # for comparison)----\n",
    "# print(\"Original test with test set - classification report\")\n",
    "# print(classification_report(y_test, clf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
