## Notes
- *Please remember to clear all Jupyter outputs before pushing.* 

## Data files
- `995,000_rows.csv` is the full dataset and is available on Absalon.
- `995,000_rows_preprocessed_train.csv` is the training data from the full preprocessed dataset and is available on Dropbox here: https://www.dropbox.com/scl/fi/pypux16emha4xxmxdur1k/995-000_rows_preprocessed_train.csv?rlkey=6jdtmggb8dr6qylgswoc2cf2h&st=o5x5a8zi&dl=0
- `995,000_rows_preprocessed_valid.csv` is the validation data from the full preprocessed dataset and is available on Dropbox here: https://www.dropbox.com/scl/fi/c8845w5vr2k087f7e1ii1/995-000_rows_preprocessed_valid.csv?rlkey=ao7se9oo8jfd53djdm32b83ju&st=7df2uig1&dl=0
- `995,000_rows_preprocessed_test.csv` is the training data from the full preprocessed dataset and is available on Dropbox here: https://www.dropbox.com/scl/fi/huzi9hmf26bjzi1s3z9qu/995-000_rows_preprocessed_test.csv?rlkey=x0cazpvn6vx8lx8zu2m1fefkc&st=2f1nvm15&dl=0
Alternatively you can run the preprocessing code on the full dataset and create the preprocessed dataset locally. It will take approximately two hours.
- `15,000_rows.csv` is a large sample of the full dataset that can be used when we want to run our preprocessing pipeline on a dataset of decent size, but we do not want it to take hours to run. 
- `15,000_rows_preprocessed_train.csv` is the training data from a preprocessed sample of the full dataset that can be used when we want to work with the preprocessed data, but the preprocessed full dataset is too heavy.
- `15,000_rows_preprocessed_valid.csv` is the validation data from a preprocessed sample of the full dataset that can be used when we want to work with the preprocessed data, but the preprocessed full dataset is too heavy.
- `15,000_rows_preprocessed_test.csv` is the test data from a preprocessed sample of the full dataset that can be used when we want to work with the preprocessed data, but the preprocessed full dataset is too heavy.
- `250_rows.csv` is a small sample of the full dataset that is used for part 1, task 1.
- `250_rows_preprocessed.csv` is the preprocessed small sample of the full dataset that is used for part 1, task 1.

## Other files
- `preprocessing.pdf` is the output of the preprocessing pipeline run on the full dataset.
