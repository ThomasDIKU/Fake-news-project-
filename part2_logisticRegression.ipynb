{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\**See report*\\*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import ast\n",
    "import joblib\n",
    "\n",
    "# Download nltk packages if necessary\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Load data and map article types to either \"fake\" or \"reliable\" ----\n",
    "\n",
    "# Mapping of types to \"fake\" or \"reliable\"\n",
    "type_mapping = {\n",
    "    'unreliable': 'fake',\n",
    "    'fake': 'fake',\n",
    "    'conspiracy': 'fake',\n",
    "    'bias': 'fake',\n",
    "    'junksci': 'fake',\n",
    "    'clickbait': 'reliable',\n",
    "    'reliable' : 'reliable',\n",
    "    'state': 'fake',\n",
    "    'political': 'reliable',\n",
    "    'satire': 'fake',\n",
    "    'hate': 'fake',\n",
    "    'rumor': 'fake',\n",
    "}\n",
    "\n",
    "# Load data and include only relevant columns\n",
    "#data_train = pd.read_csv(\"fakenewscorpus_data/15,000_rows_preprocessed_train.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "#data_valid = pd.read_csv(\"fakenewscorpus_data/15,000_rows_preprocessed_valid.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "#data_test = pd.read_csv(\"fakenewscorpus_data/15,000_rows_preprocessed_test.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "data_train = pd.read_csv(\"fakenewscorpus_data/995,000_rows_preprocessed_train.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "data_valid = pd.read_csv(\"fakenewscorpus_data/995,000_rows_preprocessed_valid.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "data_test = pd.read_csv(\"fakenewscorpus_data/995,000_rows_preprocessed_test.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "\n",
    "\n",
    "# Map types to labels\n",
    "data_train[\"label\"] = data_train[\"type\"].map(type_mapping)\n",
    "data_valid[\"label\"] = data_valid[\"type\"].map(type_mapping)\n",
    "data_test[\"label\"] = data_test[\"type\"].map(type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "fake        286875\n",
      "reliable    121335\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if data is balanced\n",
    "print(data_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each class\n",
    "count_fake = sum(data_train['label'] == 'fake')\n",
    "count_reliable = sum(data_train['label'] == 'reliable')\n",
    "\n",
    "# Determine how many rows with 'fake' to keep\n",
    "rows_to_keep = count_reliable\n",
    "\n",
    "# Randomly sample rows with label 'fake'\n",
    "df_fake = data_train[data_train['label'] == 'fake'].sample(n=rows_to_keep, random_state=42)\n",
    "df_reliable = data_train[data_train['label'] == 'reliable']  # Keep all rows with 'reliable'\n",
    "\n",
    "# Combine the two classes back into a balanced dataframe\n",
    "data_train = pd.concat([df_fake, df_reliable])\n",
    "\n",
    "# Shuffle the resulting dataframe to mix the rows (optional)\n",
    "data_train = data_train.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "reliable    121335\n",
       "fake        121335\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if data is balanced - again\n",
    "data_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the top 10,000 words\n",
    "\n",
    "content_as_lists = data_train['content'].apply(ast.literal_eval)\n",
    "\n",
    "all_words = content_as_lists.explode().tolist()\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "top_10000_words = [word for word, _ in word_counts.most_common(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save top 10,000_words as file\n",
    "\n",
    "import json\n",
    "\n",
    "# Save as JSON-file\n",
    "with open(\"misc/top_10000_words.json\", \"w\", encoding=\"utf-8\") as fil:\n",
    "    json.dump(top_10000_words, fil)\n",
    "\n",
    "print(\"List saved in the file 'top_10000_words.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'content' to Bag-of-Words feature matrix\n",
    "vectorizer = CountVectorizer(vocabulary=top_10000_words)\n",
    "\n",
    "X_train = vectorizer.transform(data_train['content'])\n",
    "X_valid = vectorizer.transform(data_valid['content'])\n",
    "X_test = vectorizer.transform(data_test['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Extract labels\n",
    "y_train = data_train['label']\n",
    "y_valid = data_valid['label']\n",
    "y_test = data_test['label']\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=100000, solver='saga', random_state=42)\n",
    "logistic_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 'X_test_scaled' and 'y_test' as files, so they can be \n",
    "# used in part 4 (evaluation)\n",
    "\n",
    "sparse.save_npz(\"misc/X_test_scaled.npz\", X_test_scaled)\n",
    "\n",
    "y_test.to_csv('misc/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with validation data\n",
    "y_pred = logistic_model.predict(X_valid_scaled)\n",
    "\n",
    "f1 = f1_score(y_valid, y_pred, average='weighted')\n",
    "print(\"Total F1-score:\", f1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as a file\n",
    "joblib.dump(logistic_model, 'misc/logistic_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\**See report*\\*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Load BBC-data and add to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate BBC data\n",
    "bbc_data = pd.read_csv(\"BBC_data/BBC_preprocessed.csv\", usecols=[\"content\", \"type\"], dtype=str)\n",
    "data_train_with_BBC = pd.concat([data_train, bbc_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 10,000 words\n",
    "\n",
    "content_as_lists = data_train_with_BBC['content'].apply(ast.literal_eval)\n",
    "\n",
    "all_words = content_as_lists.explode().tolist()\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "top_10000_words = [word for word, _ in word_counts.most_common(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'content' to Bag-of-Words feature matrix\n",
    "vectorizer = CountVectorizer(vocabulary=top_10000_words)\n",
    "\n",
    "X_train = vectorizer.transform(data_train['content'])\n",
    "X_valid = vectorizer.transform(data_valid['content'])\n",
    "X_test = vectorizer.transform(data_test['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Extract labels\n",
    "y_train = data_train['label']\n",
    "y_valid = data_valid['label']\n",
    "y_test = data_test['label']\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=100000, solver='saga', random_state=42)\n",
    "logistic_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with validation\n",
    "y_pred = logistic_model.predict(X_valid_scaled)\n",
    "\n",
    "f1 = f1_score(y_valid, y_pred, average='weighted')\n",
    "print(\"Total F1-score:\", f1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
